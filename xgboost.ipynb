{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indebtedness Case Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# Models\n",
    "import xgboost as xgb\n",
    "\n",
    "# Tools\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding methods and attributes to pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform(self):  \n",
    "    # Encoding all the features as int, and saving an encoder by column\n",
    "    return self.apply(lambda x: self.dict_encoder[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(self):\n",
    "    # Retriving value before encoding\n",
    "    return self.apply(lambda x: self.dict_encoder[x.name].inverse_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(self):\n",
    "    # Filling NAs\n",
    "    return self.fillna(self.mean()).fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overriting pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_and_attributes = {\n",
    "    'clean' : clean,\n",
    "    'dict_encoder' : defaultdict(LabelEncoder),\n",
    "    'fit_transform' : fit_transform,\n",
    "    'inverse_transform' : inverse_transform\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ma in methods_and_attributes.keys():\n",
    "    setattr(pd.DataFrame, ma, methods_and_attributes[ma])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "test = pd.read_csv('data/test.csv', index_col='id', na_values=['\\\\N', 'Non Renseigne'])\n",
    "train = pd.read_csv('data/train.csv', index_col='id', na_values=['\\\\N', 'Non Renseigne'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all the columns with more than 80% of NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the cols\n",
    "train = train.dropna(thresh=0.2*len(train), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the same columns than train\n",
    "test = test[[column for column in train.columns if column != 'ORIENTATION']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting it into X and y parts\n",
    "X_train = train.drop('ORIENTATION', axis=1)\n",
    "y_train = train['ORIENTATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning dataframes\n",
    "X_train = X_train.clean()\n",
    "test = test.clean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding dataframes\n",
    "X_train = X_train.fit_transform()\n",
    "test = test.fit_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting train to create new dataframes, in order to be able to do local tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating local train and test\n",
    "local_X_train, local_X_test, local_y_train, local_y_test = \\\n",
    "    train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Surendettement                   0.421493\n",
       "Accompagnement                   0.402884\n",
       "Mediation                        0.085601\n",
       "Aucune                           0.080251\n",
       "Autres Proc√©dures Collectives    0.008607\n",
       "Microcredit                      0.001163\n",
       "Name: ORIENTATION, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the local dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try xgboost !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgb.XGBClassifier(objective='multi:softprob', n_estimators=100, learning_rate=0.05, n_jobs=4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'min_child_weight': [1, 10],\n",
    "        'gamma': [0.5, 5],\n",
    "        'subsample': [0.6, 1.0],\n",
    "        'colsample_bytree': [0.6, 1.0],\n",
    "        'max_depth': [3, 5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(xgb_clf, parameters, cv=5, verbose=10, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/borisghidaglia/.local/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 3 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=8)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed: 15.2min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed: 21.2min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed: 25.5min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed: 33.0min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed: 39.2min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed: 45.0min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed: 55.0min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed: 66.1min\n",
      "[Parallel(n_jobs=8)]: Done 160 out of 160 | elapsed: 81.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=4, nthread=None, objective='multi:softprob', random_state=42,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=8,\n",
       "       param_grid={'min_child_weight': [1, 10], 'gamma': [0.5, 5], 'subsample': [0.6, 1.0], 'colsample_bytree': [0.6, 1.0], 'max_depth': [3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(local_X_train, local_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.6, gamma=0.5, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=100, n_jobs=4, nthread=None,\n",
       "       objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5651162790697675"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_.score(local_X_test, local_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5755813953488372"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf.best_estimator_.score(local_X_test, local_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we have to train our model on the entire train dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.best_estimator_.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame(index=test.index, data={'ORIENTATION':clf.best_estimator_.predict(test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res.to_csv('submissions/submission_3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
